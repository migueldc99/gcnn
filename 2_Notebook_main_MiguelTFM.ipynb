{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qCEysw0VlPa-"
   },
   "source": [
    "First, we install the required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 923530,
     "status": "ok",
     "timestamp": 1661941269974,
     "user": {
      "displayName": "Miguel Dalmau Casañal",
      "userId": "18435987340009841788"
     },
     "user_tz": -120
    },
    "id": "r9_TOhzvCt62",
    "outputId": "ec527690-3a67-4a6b-c2e9-42fc382605df"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Looking in links: https://data.pyg.org/whl/torch-+.html\n",
      "Collecting torch-scatter\n",
      "  Downloading torch_scatter-2.0.9.tar.gz (21 kB)\n",
      "Building wheels for collected packages: torch-scatter\n",
      "  Building wheel for torch-scatter (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for torch-scatter: filename=torch_scatter-2.0.9-cp37-cp37m-linux_x86_64.whl size=274491 sha256=c2528781ddab4e4625bee364bffd309f75836ca58456b4c2dc85b91149770028\n",
      "  Stored in directory: /root/.cache/pip/wheels/dd/57/a3/42ea193b77378ce634eb9454c9bc1e3163f3b482a35cdee4d1\n",
      "Successfully built torch-scatter\n",
      "Installing collected packages: torch-scatter\n",
      "Successfully installed torch-scatter-2.0.9\n",
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Looking in links: https://data.pyg.org/whl/torch-+.html\n",
      "Collecting torch-sparse\n",
      "  Downloading torch_sparse-0.6.15.tar.gz (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 4.3 MB/s \n",
      "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from torch-sparse) (1.7.3)\n",
      "Requirement already satisfied: numpy<1.23.0,>=1.16.5 in /usr/local/lib/python3.7/dist-packages (from scipy->torch-sparse) (1.21.6)\n",
      "Building wheels for collected packages: torch-sparse\n",
      "  Building wheel for torch-sparse (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for torch-sparse: filename=torch_sparse-0.6.15-cp37-cp37m-linux_x86_64.whl size=516860 sha256=da78f6ce81fd9611432b36d0d5319a49fddf09ed3d754f79bfeb5c5c40b41807\n",
      "  Stored in directory: /root/.cache/pip/wheels/15/68/4d/1414be5c2c622bad35364e13213180797717b6d4b8923936dc\n",
      "Successfully built torch-sparse\n",
      "Installing collected packages: torch-sparse\n",
      "Successfully installed torch-sparse-0.6.15\n",
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Collecting torch-geometric\n",
      "  Downloading torch_geometric-2.1.0.post1.tar.gz (467 kB)\n",
      "\u001b[K     |████████████████████████████████| 467 kB 4.1 MB/s \n",
      "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (4.64.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (1.21.6)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (1.7.3)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (2.11.3)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (2.23.0)\n",
      "Requirement already satisfied: pyparsing in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (3.0.9)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (1.0.2)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->torch-geometric) (2.0.1)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (2022.6.15)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (1.24.3)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->torch-geometric) (3.1.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->torch-geometric) (1.1.0)\n",
      "Building wheels for collected packages: torch-geometric\n",
      "  Building wheel for torch-geometric (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for torch-geometric: filename=torch_geometric-2.1.0.post1-py3-none-any.whl size=689859 sha256=d993b10ac5af0190291372b321b7b7efcfa77c18bbcb2888df3b9ea070c24b72\n",
      "  Stored in directory: /root/.cache/pip/wheels/d1/cb/43/f7f2e472de4d7cff31bceddadc36d634e1e545fbc17961c282\n",
      "Successfully built torch-geometric\n",
      "Installing collected packages: torch-geometric\n",
      "Successfully installed torch-geometric-2.1.0.post1\n"
     ]
    }
   ],
   "source": [
    "!pip install torch-scatter -f https://data.pyg.org/whl/torch-${TORCH}+${CUDA}.html\n",
    "!pip install torch-sparse -f https://data.pyg.org/whl/torch-${TORCH}+${CUDA}.html\n",
    "!pip install torch-geometric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 633
    },
    "executionInfo": {
     "elapsed": 8359,
     "status": "ok",
     "timestamp": 1661941278322,
     "user": {
      "displayName": "Miguel Dalmau Casañal",
      "userId": "18435987340009841788"
     },
     "user_tz": -120
    },
    "id": "kTrFa3cthbQ3",
    "outputId": "f57b3fdf-913d-49ae-bdc1-83415890712c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Collecting mendeleev\n",
      "  Downloading mendeleev-0.10.0-py3-none-any.whl (179 kB)\n",
      "\u001b[K     |████████████████████████████████| 179 kB 4.2 MB/s \n",
      "\u001b[?25hCollecting colorama<0.5.0,>=0.4.4\n",
      "  Downloading colorama-0.4.5-py2.py3-none-any.whl (16 kB)\n",
      "Requirement already satisfied: numpy<2.0,>=1.21 in /usr/local/lib/python3.7/dist-packages (from mendeleev) (1.21.6)\n",
      "Requirement already satisfied: SQLAlchemy<2.0.0,>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from mendeleev) (1.4.40)\n",
      "Collecting pyfiglet<0.9,>=0.8.post1\n",
      "  Downloading pyfiglet-0.8.post1-py2.py3-none-any.whl (865 kB)\n",
      "\u001b[K     |████████████████████████████████| 865 kB 51.2 MB/s \n",
      "\u001b[?25hRequirement already satisfied: six<2.0.0,>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from mendeleev) (1.15.0)\n",
      "Collecting Pygments<3.0.0,>=2.8.0\n",
      "  Downloading Pygments-2.13.0-py3-none-any.whl (1.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.1 MB 46.8 MB/s \n",
      "\u001b[?25hRequirement already satisfied: pandas>=0.25.0 in /usr/local/lib/python3.7/dist-packages (from mendeleev) (1.3.5)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.25.0->mendeleev) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.25.0->mendeleev) (2022.2.1)\n",
      "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from SQLAlchemy<2.0.0,>=1.4.0->mendeleev) (4.12.0)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.7/dist-packages (from SQLAlchemy<2.0.0,>=1.4.0->mendeleev) (1.1.3)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->SQLAlchemy<2.0.0,>=1.4.0->mendeleev) (3.8.1)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->SQLAlchemy<2.0.0,>=1.4.0->mendeleev) (4.1.1)\n",
      "Installing collected packages: Pygments, pyfiglet, colorama, mendeleev\n",
      "  Attempting uninstall: Pygments\n",
      "    Found existing installation: Pygments 2.6.1\n",
      "    Uninstalling Pygments-2.6.1:\n",
      "      Successfully uninstalled Pygments-2.6.1\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "ipython 7.9.0 requires jedi>=0.10, which is not installed.\u001b[0m\n",
      "Successfully installed Pygments-2.13.0 colorama-0.4.5 mendeleev-0.10.0 pyfiglet-0.8.post1\n"
     ]
    },
    {
     "data": {
      "application/vnd.colab-display-data+json": {
       "pip_warning": {
        "packages": [
         "pygments"
        ]
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "!pip install mendeleev"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4PqTt1L9y9NP"
   },
   "source": [
    "And then, we import all required modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2995,
     "status": "ok",
     "timestamp": 1661943103038,
     "user": {
      "displayName": "Miguel Dalmau Casañal",
      "userId": "18435987340009841788"
     },
     "user_tz": -120
    },
    "id": "cDEgjoSnvKKa",
    "outputId": "b89a1d06-e28c-4b6a-8202-7915a7a127c2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "import pdb\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch_geometric.loader import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import yaml\n",
    "import markdown\n",
    "import os\n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "sys.path.append('/content/drive/MyDrive/Colab Notebooks/MoleculeDB')\n",
    "\n",
    "from callbacks import set_up_callbacks\n",
    "from count_model_parameters import count_model_parameters\n",
    "from features import set_up_features\n",
    "from graph_potential import graph_potential\n",
    "from molecule_graph_dataset import MoleculeGraphDataSet\n",
    "from fit_model import fit_model\n",
    "from set_up_molecular_graphs import set_up_molecular_graphs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bxswG5lTzIWb"
   },
   "source": [
    "A driver script to fit a Graph Convolutional Neural Network GCNN model to\n",
    "represent properties of molecular/condensed matter systems.\n",
    "\n",
    "To execute: python fit_graph.py input-file\n",
    "\n",
    "where input-file is a yaml file specifying different parameters of the\n",
    "model and how the job is to be run. For an example see sample.yml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1661943103038,
     "user": {
      "displayName": "Miguel Dalmau Casañal",
      "userId": "18435987340009841788"
     },
     "user_tz": -120
    },
    "id": "KHEIjcehzNN3"
   },
   "outputs": [],
   "source": [
    "# input_file is a yaml compliant file\n",
    "input_file = '/content/drive/MyDrive/Colab Notebooks/MoleculeDB/sample.yml'\n",
    "\n",
    "with open( input_file, 'r' ) as input_stream:\n",
    "    input_data = yaml.load(input_stream, Loader=yaml.Loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rd9i-74r1-we"
   },
   "source": [
    "Debug: we read it from yaml file; if it is set True, the debugging process begins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1661943103447,
     "user": {
      "displayName": "Miguel Dalmau Casañal",
      "userId": "18435987340009841788"
     },
     "user_tz": -120
    },
    "id": "YeAYGcsm2SZx"
   },
   "outputs": [],
   "source": [
    "debug = input_data.get(\"debug\", False)\n",
    "\n",
    "if debug:\n",
    "    pdb.set_trace()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X_f6m8iT7LbG"
   },
   "source": [
    "We assign the loaded data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1661943105290,
     "user": {
      "displayName": "Miguel Dalmau Casañal",
      "userId": "18435987340009841788"
     },
     "user_tz": -120
    },
    "id": "4_haxBZ669f1"
   },
   "outputs": [],
   "source": [
    "nGraphConvolutionLayers = input_data.get(\"nGraphConvolutionLayers\", 1)\n",
    "nFullyConnectedLayers = input_data.get(\"nFullyConnectedLayers\", 1)\n",
    "nMaxNeighbours = input_data.get(\"nMaxNeighbours\", 6)\n",
    "useCovalentRadii = input_data.get(\"useCovalentRadii\", False)\n",
    "nodeFeatures = input_data.get(\"nodeFeatures\", [\"atomic_number\"])\n",
    "nTotalNodeFeatures = input_data.get(\"nTotalNodeFeatures\", 10)\n",
    "nNeurons = input_data.get(\"nNeurons\", None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UXVEClLf7T98"
   },
   "source": [
    "We read and set up the edge, bond-angle and dihedral-angle features we work with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1661943106648,
     "user": {
      "displayName": "Miguel Dalmau Casañal",
      "userId": "18435987340009841788"
     },
     "user_tz": -120
    },
    "id": "cjxhNmzw7US6"
   },
   "outputs": [],
   "source": [
    "edges, bond_angle, dihedral_angle = set_up_features(input_data)\n",
    "\n",
    "edge_parameters = edges.parameters()\n",
    "bond_angle_parameters = bond_angle.parameters()\n",
    "\n",
    "if dihedral_angle:\n",
    "    dihedral_angle_parameters = dihedral_angle.parameters()\n",
    "\n",
    "# now the total number of edge features is given by the sum\n",
    "# of edges features + 2 * bond_angle features + dihedral_angle features\n",
    "# all these features define the edge entries\n",
    "\n",
    "nTotalEdgeFeatures = edges.n_features() + 2 * bond_angle.n_features()\n",
    "if dihedral_angle:\n",
    "    nTotalEdgeFeatures += dihedral_angle.n_features()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "68byexRc8T0l"
   },
   "source": [
    "Now, we define our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1661943108016,
     "user": {
      "displayName": "Miguel Dalmau Casañal",
      "userId": "18435987340009841788"
     },
     "user_tz": -120
    },
    "id": "j-G9tjVv8Z7Q"
   },
   "outputs": [],
   "source": [
    "model = graph_potential(\n",
    "    n_gc_layers=nGraphConvolutionLayers,\n",
    "    n_fc_layers=nFullyConnectedLayers,\n",
    "    n_node_features=nTotalNodeFeatures,\n",
    "    n_edge_features=nTotalEdgeFeatures,\n",
    "    n_neurons=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "71z00BQT83AL"
   },
   "source": [
    "Escribimos cosas con logtext (DUDA AQUÍ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1661943109281,
     "user": {
      "displayName": "Miguel Dalmau Casañal",
      "userId": "18435987340009841788"
     },
     "user_tz": -120
    },
    "id": "9mOhFFY987ki"
   },
   "outputs": [],
   "source": [
    "log_text = \"\\n# Model Description  \\n\"\n",
    "log_text += \"- nGraphConvolutionLayers: \" + repr(nGraphConvolutionLayers) + \"  \\n\"\n",
    "log_text += \"- nFullyConnectedLayers: \" + repr(nFullyConnectedLayers) + \"  \\n\"\n",
    "if useCovalentRadii:\n",
    "    log_text += \"- Using Covalent Radii to find neighbours \\n\"\n",
    "else:\n",
    "    log_text += \"- nMaxNeighbours: \" + repr(nMaxNeighbours) + \"  \\n\"\n",
    "log_text += \"- nTotalNodeFeatures: \" + repr(nTotalNodeFeatures) + \"  \\n\"\n",
    "log_text += \"- physical nodeFeatures: \" + repr(nodeFeatures) + \"  \\n\"\n",
    "log_text += \"- nEdgeFeatures: \" + repr(nTotalEdgeFeatures) + \"  \\n\"\n",
    "log_text += \"- Edge r_min: \" + repr(edge_parameters[\"x_min\"]) + \" Angstrom  \\n\"\n",
    "log_text += \"- Edge r_max: \" + repr(edge_parameters[\"x_max\"]) + \" Angstrom  \\n\"\n",
    "log_text += \"- Edge nFeatures: \" + repr(edge_parameters[\"n_features\"]) + \" \\n\"\n",
    "log_text += \"- Edge sigma: \" + repr(edge_parameters[\"sigma\"]) + \" Angstrom  \\n\"\n",
    "log_text += \"- Bond-Angle min: \" + repr(bond_angle_parameters[\"x_min\"]) + \" radians  \\n\"\n",
    "log_text += \"- Bond-Angle max: \" + repr(bond_angle_parameters[\"x_max\"]) + \" radians  \\n\"\n",
    "log_text += \"- Bond-Angle nFeatures: \" + repr(bond_angle_parameters[\"n_features\"]) + \" \\n\"\n",
    "log_text += \"- Bond-Angle sigma: \" + repr(bond_angle_parameters[\"sigma\"]) + \" radians  \\n\"\n",
    "log_text += \"- Bond-Angle normalised: \" + repr(bond_angle_parameters[\"norm\"]) + \"   \\n\"\n",
    "if dihedral_angle:\n",
    "    log_text += \"- Dihedral-Angle min: \" + repr(dihedral_angle_parameters[\"x_min\"]) + \" radians  \\n\"\n",
    "    log_text += \"- Dihedral-Angle max: \" + repr(dihedral_angle_parameters[\"x_max\"]) + \" radians  \\n\"\n",
    "    log_text += \"- Dihedral-Angle nFeatures: \" + repr(dihedral_angle_parameters[\"n_features\"]) + \" \\n\"\n",
    "    log_text += \"- Dihedral-Angle sigma: \" + repr(dihedral_angle_parameters[\"sigma\"]) + \" radians  \\n\"\n",
    "    log_text += \"- Dihedral-Angle normalised: \" + repr(dihedral_angle_parameters[\"norm\"]) + \"   \\n\"\n",
    "\n",
    "nParameters = count_model_parameters(model)\n",
    "log_text += \"- This model contains a total of: \" + repr(nParameters) + \" adjustable parameters  \\n\"\n",
    "\n",
    "nEpochs = input_data.get(\"nEpochs\", 100)\n",
    "nBatch = input_data.get(\"nBatch\", 50)\n",
    "chkptFreq = input_data.get(\"nCheckpoint\", 10)\n",
    "learningRate = input_data.get(\"learningRate\", 1.0e-3)\n",
    "seed = input_data.get(\"randomSeed\", 42)\n",
    "nTrainMaxEntries = input_data.get(\"nTrainMaxEntries\", None)\n",
    "nValMaxEntries = input_data.get(\"nValMaxEntries\", None)\n",
    "\n",
    "log_text += \"# Relaxation process  \\n\"\n",
    "log_text += \"- nEpochs: \" + repr(nEpochs) + \"  \\n\"\n",
    "log_text += \"- nBatch: \" + repr(nBatch) + \"  \\n\"\n",
    "log_text += \"- Checkpointing model and optimizer every \" + repr(chkptFreq) + \" epochs  \\n\"\n",
    "log_text += \"- learningRate: \" + repr(learningRate) + \"  \\n\"\n",
    "log_text += \"- random seed: \" + repr(seed) + \"  \\n\"\n",
    "\n",
    "graphType = input_data.get(\"graphType\", \"covalent\")\n",
    "log_text += \"- graph construction style: \" + graphType + \"  \\n\"\n",
    "\n",
    "if nTrainMaxEntries:\n",
    "    log_text += \"- Size of training database: \" + repr(nTrainMaxEntries) + \"  \\n\"\n",
    "else:\n",
    "    log_text += \"- Using full training database \\n\"\n",
    "if nValMaxEntries:\n",
    "    log_text += \"- Size of validation/test database: \" + repr(nValMaxEntries) + \"  \\n\"\n",
    "else:\n",
    "    log_text += \"- Using full validation/test database  \\n\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XY-25PMDA176"
   },
   "source": [
    "Se pueden incluir fuerzas o no, de hecho no está implementado aunque igual estaría bien ponerlo cómo posible evolución del programa para poder predecir dinámica molecular por ejemplo.\n",
    "\n",
    "Lo de loadModel sí está implementado y sirve para cargar un modelo si nos hemos quedado a mitad de simulación o similar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1661943111694,
     "user": {
      "displayName": "Miguel Dalmau Casañal",
      "userId": "18435987340009841788"
     },
     "user_tz": -120
    },
    "id": "Wv-aALtJ9tZI"
   },
   "outputs": [],
   "source": [
    "calculateForces = input_data.get(\"calculateForces\", False)\n",
    "loadModel = input_data.get(\"loadModel\", False)\n",
    "\n",
    "log_text += \"- Using forces in fitting: \" + repr(calculateForces) + \"  \\n\"\n",
    "\n",
    "if loadModel:\n",
    "    loadModelFileName = input_data[\"loadModelFileName\"]\n",
    "    log_text += \"- Starting from previous model: \" + loadModelFileName + \"  \\n\"\n",
    "else:\n",
    "    log_text += \"- Initialising model parameters from scratch   \\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "executionInfo": {
     "elapsed": 490,
     "status": "ok",
     "timestamp": 1661943114073,
     "user": {
      "displayName": "Miguel Dalmau Casañal",
      "userId": "18435987340009841788"
     },
     "user_tz": -120
    },
    "id": "FfgMxbV790Nd"
   },
   "outputs": [],
   "source": [
    "descriptionText = input_data.get(\"descriptionText\", \" \")\n",
    "\n",
    "descriptionText += log_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V0d5ien-96RK"
   },
   "source": [
    "We introduce the path to the data files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1661943114510,
     "user": {
      "displayName": "Miguel Dalmau Casañal",
      "userId": "18435987340009841788"
     },
     "user_tz": -120
    },
    "id": "AT9IvzIw92Vw"
   },
   "outputs": [],
   "source": [
    "trainDir = input_data.get(\"trainDir\", \"/content/drive/MyDrive/Colab Notebooks/MoleculeDB/training_set\")\n",
    "valDir = input_data.get(\"valDir\", \"/content/drive/MyDrive/Colab Notebooks/MoleculeDB/validation_set\")\n",
    "testDir = input_data.get(\"testDir\", \"/content/drive/MyDrive/Colab Notebooks/MoleculeDB/test_set\")\n",
    "directories = [trainDir, valDir, testDir]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1661943116031,
     "user": {
      "displayName": "Miguel Dalmau Casañal",
      "userId": "18435987340009841788"
     },
     "user_tz": -120
    },
    "id": "zNN5MSbOzfGc"
   },
   "outputs": [],
   "source": [
    "transformData = input_data.get(\"transformData\", False)\n",
    "# transform = SetUpDataTransform( transformData, directories )\n",
    "transform = None\n",
    "\n",
    "if transform:\n",
    "    log_text += \"- Using data transformation \" + transformData + \"   \\n\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E65XuLHx-iQh"
   },
   "source": [
    "At this point, we obtain the corresponding graphs from each molecule file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "executionInfo": {
     "elapsed": 514,
     "status": "ok",
     "timestamp": 1661943117784,
     "user": {
      "displayName": "Miguel Dalmau Casañal",
      "userId": "18435987340009841788"
     },
     "user_tz": -120
    },
    "id": "LpjNKJ2g-xJQ"
   },
   "outputs": [],
   "source": [
    "Graphs = set_up_molecular_graphs(\n",
    "    graphType,\n",
    "    edge_features=edges,\n",
    "    bond_angle_features=bond_angle,\n",
    "    dihedral_features=dihedral_angle,\n",
    "    node_feature_list=nodeFeatures,\n",
    "    n_total_node_features=nTotalNodeFeatures)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ohy82d9J_M7r"
   },
   "source": [
    "Now, we prepare the graph dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "executionInfo": {
     "elapsed": 245923,
     "status": "ok",
     "timestamp": 1661943364996,
     "user": {
      "displayName": "Miguel Dalmau Casañal",
      "userId": "18435987340009841788"
     },
     "user_tz": -120
    },
    "id": "Ag5RQpbj_R5D"
   },
   "outputs": [],
   "source": [
    "trainDataset = MoleculeGraphDataSet(\n",
    "    trainDir, Graphs, nMaxEntries=nTrainMaxEntries, seed=seed, transform=transform\n",
    ")\n",
    "\n",
    "if nTrainMaxEntries:\n",
    "    nTrain = nTrainMaxEntries\n",
    "else:\n",
    "    nTrain = len(trainDataset)\n",
    "\n",
    "valDataset = MoleculeGraphDataSet(\n",
    "    valDir, Graphs, nMaxEntries=nValMaxEntries, seed=seed, transform=transform\n",
    ")\n",
    "\n",
    "if nValMaxEntries:\n",
    "    nValidation = nValMaxEntries\n",
    "else:\n",
    "    nValidation = len(valDataset)\n",
    "\n",
    "testDataset = MoleculeGraphDataSet(\n",
    "    testDir, Graphs, nMaxEntries=nValMaxEntries, seed=seed, transform=transform\n",
    ")\n",
    "\n",
    "trainLoader = DataLoader(trainDataset, batch_size=nBatch, num_workers=0)\n",
    "valLoader = DataLoader(valDataset, batch_size=nBatch, num_workers=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OECYC4xx_aC2"
   },
   "source": [
    "We define a tensorboard writer to monitor the fitting process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1661943364997,
     "user": {
      "displayName": "Miguel Dalmau Casañal",
      "userId": "18435987340009841788"
     },
     "user_tz": -120
    },
    "id": "1MaunjnS_ZME"
   },
   "outputs": [],
   "source": [
    "timeString = datetime.now().strftime(\"%d%m%Y-%H%M%S\")\n",
    "fileName = \"5dihedralfeat-\" + repr(nMaxNeighbours) + \"nn-\" + repr(nGraphConvolutionLayers) + \"gcl-\" + repr(nFullyConnectedLayers) + \"fcl\"\n",
    "logFile = \"/content/drive/MyDrive/Colab Notebooks/MoleculeDB/runs/\" + fileName + \"-\" + timeString\n",
    "\n",
    "saveModelFileName = (\n",
    "    \"GraphPotential-\"\n",
    "    + repr(nMaxNeighbours)\n",
    "    + \"nn-\"\n",
    "    + repr(nGraphConvolutionLayers)\n",
    "    + \"gcl-\"\n",
    "    + repr(nFullyConnectedLayers)\n",
    "    + \"fcl-\"\n",
    "    + timeString\n",
    "    + \".tar\"\n",
    ")\n",
    "\n",
    "writer = SummaryWriter(logFile)\n",
    "\n",
    "description = markdown.markdown(descriptionText)\n",
    "\n",
    "writer.add_text(\"Description\", description)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nao1Eck8_tvK"
   },
   "source": [
    "Optimizier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1661943364997,
     "user": {
      "displayName": "Miguel Dalmau Casañal",
      "userId": "18435987340009841788"
     },
     "user_tz": -120
    },
    "id": "yBcnGGRu_q85"
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=learningRate)\n",
    "\n",
    "# if we are to use a pre-saved model and optimizer, load their parameters here\n",
    "\n",
    "if loadModel:\n",
    "\n",
    "    # model = torch.load( loadModelFileName )\n",
    "\n",
    "    checkpoint = torch.load(loadModelFileName)\n",
    "\n",
    "    model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "    optimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"])\n",
    "    n_start = checkpoint[\"epoch\"]\n",
    "\n",
    "else:\n",
    "\n",
    "    n_start = 0\n",
    "\n",
    "lossFunction = torch.nn.MSELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SZ1DXvKpAF51"
   },
   "source": [
    "Now, we set-up the callbacks, if any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1661943364998,
     "user": {
      "displayName": "Miguel Dalmau Casañal",
      "userId": "18435987340009841788"
     },
     "user_tz": -120
    },
    "id": "VnatemWUANHY"
   },
   "outputs": [],
   "source": [
    "anyCallBacks = input_data.get(\"callbacks\", None)\n",
    "\n",
    "callbacks = set_up_callbacks(anyCallBacks, optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fCuUb3fNAW4J"
   },
   "source": [
    "Training process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "J_v3ObFwASJC",
    "outputId": "e3457c92-4848-4de7-b6ac-82accb60a577"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      train-loss      validation-loss\n",
      "------------------------------------------\n",
      "0,61859.25128746033,1594.6965265274048\n",
      "1,1436.6725668907166,1584.2344427108765\n",
      "2,1419.558138847351,1569.3140506744385\n",
      "3,1394.1006126403809,1552.2652769088745\n",
      "4,1357.2668256759644,1520.2881956100464\n",
      "5,1287.7611966133118,1418.2551050186157\n",
      "6,1080.4236857891083,1045.6035375595093\n",
      "7,780.2718715667725,746.5925002098083\n",
      "8,573.1636034250259,580.8906102180481\n",
      "9,452.05492329597473,468.6547780036926\n",
      "10,342.3220602273941,344.44878339767456\n",
      "11,276.01938033103943,295.0667953491211\n",
      "12,238.80330574512482,265.9241724014282\n",
      "13,211.34364545345306,238.8084065914154\n",
      "14,188.51867192983627,222.65822887420654\n",
      "15,169.35104590654373,220.48656284809113\n",
      "16,153.83321249485016,219.92170453071594\n",
      "17,141.99475413560867,213.9182686805725\n",
      "18,131.19841983914375,193.77163469791412\n",
      "19,118.4835532605648,151.18695676326752\n",
      "20,102.13494443893433,114.67133969068527\n",
      "21,88.10101741552353,100.96525728702545\n",
      "22,76.55519454181194,96.74824059009552\n",
      "23,68.08169437944889,85.96431761980057\n",
      "24,60.54058122634888,81.04059681296349\n",
      "25,56.29248674213886,76.91499382257462\n",
      "26,53.82305879890919,73.95695760846138\n",
      "27,51.94401817023754,71.6509348154068\n",
      "28,50.100074365735054,69.51169475913048\n",
      "29,48.092912904918194,65.34834325313568\n",
      "30,45.745939910411835,57.70044103264809\n",
      "31,42.77412700653076,50.78380674123764\n",
      "32,39.84856128692627,47.90087133646011\n",
      "33,38.52202922105789,45.26671275496483\n",
      "34,37.95948817580938,42.93731927871704\n",
      "35,37.298170894384384,41.82484328746796\n",
      "36,36.43004070967436,42.823323756456375\n",
      "37,35.36282900720835,46.582456678152084\n",
      "38,34.05061983317137,53.133044987916946\n",
      "39,32.477064836770296,57.97445863485336\n",
      "40,31.02994940429926,52.6385860145092\n",
      "41,29.802136108279228,40.77391937375069\n",
      "42,28.312396071851254,32.999123334884644\n",
      "43,27.205343052744865,32.574976086616516\n",
      "44,26.56578917428851,32.25751236081123\n",
      "45,26.433266330510378,30.53032509982586\n",
      "46,26.071697015315294,29.454078748822212\n",
      "47,25.476001292467117,28.832012340426445\n",
      "48,25.034924875944853,26.787820756435394\n",
      "49,24.526663649827242,25.337799191474915\n",
      "50,24.251979429274797,25.22721327841282\n",
      "51,24.097195394337177,25.209525376558304\n",
      "52,23.860115617513657,25.111344158649445\n",
      "53,23.519943803548813,25.05152814090252\n",
      "54,23.199470072984695,24.98398780822754\n",
      "55,22.821684706956148,25.016295909881592\n",
      "56,22.47818924859166,25.08831448853016\n",
      "57,22.045574437826872,25.336259976029396\n",
      "58,21.663639517500997,25.60335822403431\n",
      "59,21.2068626023829,25.890013054013252\n",
      "60,20.829908829182386,26.007018610835075\n",
      "61,20.449455792084336,25.955684334039688\n",
      "62,20.1548132263124,25.68266950547695\n",
      "63,19.831546865403652,25.257281213998795\n",
      "64,19.544069688767195,24.7767723351717\n",
      "65,19.197545263916254,24.207720831036568\n",
      "66,18.89231649786234,23.68302322924137\n",
      "67,18.535996295511723,23.04765298962593\n",
      "68,18.244145210832357,22.513659745454788\n",
      "69,17.91216702014208,21.88338115811348\n",
      "70,17.63906466215849,21.36489026248455\n",
      "71,17.268085539340973,20.278510227799416\n",
      "72,17.05907618254423,19.934353232383728\n",
      "73,16.758353166282177,19.285794124007225\n",
      "74,16.53806360065937,18.778676986694336\n",
      "75,16.284443970769644,18.272616788744926\n"
     ]
    }
   ],
   "source": [
    "print(\"epoch      train-loss      validation-loss\")\n",
    "print(\"------------------------------------------\")\n",
    "\n",
    "fit_model(\n",
    "    nEpochs,\n",
    "    model,\n",
    "    lossFunction,\n",
    "    optimizer,\n",
    "    nTrain,\n",
    "    nValidation,\n",
    "    trainLoader,\n",
    "    valLoader,\n",
    "    n_epoch_0=n_start,\n",
    "    calculate_forces=calculateForces,\n",
    "    weight=1.0e0,\n",
    "    writer=writer,\n",
    "    callbacks=callbacks,\n",
    "    check_point_path=saveModelFileName,\n",
    "    check_point_freq=chkptFreq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xfzRZdeTAzhd"
   },
   "source": [
    "Let us build a histogram of the errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vHB1xsT_A2DN"
   },
   "outputs": [],
   "source": [
    "testLoader = DataLoader(testDataset, batch_size=1, num_workers=0)\n",
    "\n",
    "print(\"         TEST SAMPLE ENERGIES             \")\n",
    "print(\"------------------------------------------\")\n",
    "\n",
    "e = []\n",
    "p = []\n",
    "\n",
    "with torch.no_grad():\n",
    "\n",
    "    file = open(logFile + \"prediction.csv\", \"w\")\n",
    "    file.write(\"exact, predicted\" + os.linesep)\n",
    "\n",
    "    for sample in testLoader:\n",
    "        \n",
    "        energy = model(sample.x, sample.edge_index, sample.edge_attr, sample.batch)\n",
    "        e.append(sample.y.item())\n",
    "        p.append(energy.item())\n",
    "        txt = repr(energy.item()) + \", \" + repr(sample.y.item())\n",
    "\n",
    "        file.write(txt + os.linesep)\n",
    "        #print(txt)\n",
    "\n",
    "    file.close()\n",
    "prediction = np.array(p)\n",
    "exact = np.array(e)\n",
    "error = prediction - exact\n",
    "\n",
    "if writer is not None:\n",
    "\n",
    "    eMax = np.max(exact)\n",
    "    eMin = np.min(exact)\n",
    "\n",
    "    x = np.linspace(eMin, eMax, 100)\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    #figPredVsExN = plt.figure()\n",
    "\n",
    "    ax.scatter(exact, prediction, color = '#0B00A8', label=\"Model predictions\")\n",
    "    ax.plot(x, x, color = 'red', label=\"Exact\")\n",
    "\n",
    "    ax.set_ylabel(r'Predicted energies', fontdict = {'fontsize':26, 'color':'k'})\n",
    "    ax.set_xlabel(r'QM9 theoretical energies', fontdict = {'fontsize':24, 'color':'k'})\n",
    "    \n",
    "    ax.legend()\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    writer.add_figure(\"Prediction vs. exact \", fig, nEpochs)\n",
    "    writer.add_histogram(\"Distribution of errors normalised data (prediction - exact)\", error)\n",
    "\n",
    "writer.close()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMhFrT9kx4scdCIEi2GC9po",
   "collapsed_sections": [],
   "name": "2_Notebook_principal.ipynb",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
